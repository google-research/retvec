{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# How to train a REWNet and export it as a compatible RetVec tokenizer model.\r\n",
    "FIXME more info"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    " %load_ext autoreload\r\n",
    " %autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np\r\n",
    "from tqdm.auto import tqdm\r\n",
    "import tensorflow as tf\r\n",
    "from termcolor import cprint\r\n",
    "from collections import defaultdict\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow.keras.optimizers import Adam\r\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\r\n",
    "\r\n",
    "from retvec.rewnet import REWCNN, REWBert, REWTCN, REWMix\r\n",
    "from retvec.utils import get_random_unicode\r\n",
    "from retvec.utils import tf_cap_memory"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "tf_cap_memory()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "max_len = 16\r\n",
    "decoder_size = 256\r\n",
    "batch_size = 128"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\r\n",
    "\r\n",
    "    def __init__(self, max_len, batch_size, decoder_size):\r\n",
    "        self.max_len = max_len\r\n",
    "        self.batch_size = batch_size\r\n",
    "        self.decoder_size = decoder_size\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        'Denotes the number of batches per epoch'\r\n",
    "        return 100000\r\n",
    "\r\n",
    "    def __getitem__(self, index):\r\n",
    "        'Generate one batch of data'\r\n",
    "        x = [get_random_unicode(self.max_len) for _ in range(self.batch_size)]\r\n",
    "        y = []\r\n",
    "        for s in x:\r\n",
    "            y.append(tf.one_hot([ord(c) for c in s], self.decoder_size))\r\n",
    "        return np.array(x), np.array(y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "train_gen = DataGenerator(max_len=max_len, batch_size=batch_size, decoder_size=decoder_size)\r\n",
    "test_gen = DataGenerator(max_len=max_len, batch_size=batch_size, decoder_size=decoder_size)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "arch = \"bert\"  # mix, bert, cnn, tcn\r\n",
    "\r\n",
    "if arch == \"bert\":\r\n",
    "    model = REWBert(decoder_size=decoder_size)\r\n",
    "    save_path  = \"../tmp/bert_auto_model\"\r\n",
    "elif arch == \"mix\":\r\n",
    "    model = REWMix(decoder_size=decoder_size)\r\n",
    "    save_path  = \"../tmp/mix_auto_model\"\r\n",
    "elif arch == \"cnn\":\r\n",
    "    model = REWCNN(decoder_size=decoder_size)\r\n",
    "    save_path  = \"../tmp/cnn_auto_model\"\r\n",
    "else:\r\n",
    "    raise ValueError(\"not implemented\")\r\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Output size extended by 1 to inject CLS token\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "token (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rec_vec (RecVec)                (None, 17, 16)       0           token[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_start (Dense)           (None, 17, 16)       272         rec_vec[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 17, 16)       32          encoder_start[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_portable ( (None, 17, 16)       6448        layer_normalization[0][0]        \n",
      "                                                                 layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 17, 16)       0           multi_head_attention_portable[0][\n",
      "                                                                 layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 17, 16)       32          add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 17, 32)       544         layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 17, 16)       528         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 17, 16)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 17, 16)       0           dropout[0][0]                    \n",
      "                                                                 layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_2 (LayerNor (None, 17, 16)       32          add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_portable_1 (None, 17, 16)       6448        layer_normalization_2[0][0]      \n",
      "                                                                 layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 17, 16)       0           multi_head_attention_portable_1[0\n",
      "                                                                 layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, 17, 16)       32          add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 17, 32)       544         layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 17, 16)       528         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 17, 16)       0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 17, 16)       0           dropout_1[0][0]                  \n",
      "                                                                 layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_4 (LayerNor (None, 17, 16)       32          add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_portable_2 (None, 17, 16)       6448        layer_normalization_4[0][0]      \n",
      "                                                                 layer_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 17, 16)       0           multi_head_attention_portable_2[0\n",
      "                                                                 layer_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_5 (LayerNor (None, 17, 16)       32          add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 17, 32)       544         layer_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 17, 16)       528         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 17, 16)       0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 17, 16)       0           dropout_2[0][0]                  \n",
      "                                                                 layer_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_6 (LayerNor (None, 17, 16)       32          add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 17, 16)       0           layer_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tokenizer (Flatten)             (None, 272)          0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem (Slici (None, 256)          0           tokenizer[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 16, 16)       0           tf.__operators__.getitem[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "decoder_batchnorm (BatchNormali (None, 16, 16)       64          reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder_1 (Conv1D)              (None, 16, 32)       8224        decoder_batchnorm[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "decoder_2 (Conv1D)              (None, 16, 128)      65664       decoder_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Conv1D)                (None, 16, 256)      33024       decoder_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 130,032\n",
      "Trainable params: 130,000\n",
      "Non-trainable params: 32\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "epochs = 5\r\n",
    "steps_per_epochs = 1000\r\n",
    "validation_steps = 50\r\n",
    "model.compile(Adam(0.002), 'binary_crossentropy')\r\n",
    "history = model.fit(train_gen, epochs=epochs, steps_per_epoch=steps_per_epochs, validation_steps=validation_steps,\r\n",
    "          validation_data=test_gen)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 47s 42ms/step - loss: 0.0060 - val_loss: 2.7909e-04\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 41s 40ms/step - loss: 2.5774e-04 - val_loss: 2.3399e-04\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 2.3637e-04 - val_loss: 2.4041e-04\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 2.4011e-04 - val_loss: 2.2581e-04\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 2.2561e-04 - val_loss: 1.8994e-04\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# bert sigmoid\r\n",
    "Epoch 1/5\r\n",
    "1000/1000 [==============================] - 47s 42ms/step - loss: 0.0060 - val_loss: 2.7909e-04\r\n",
    "Epoch 2/5\r\n",
    "1000/1000 [==============================] - 41s 40ms/step - loss: 2.5774e-04 - val_loss: 2.3399e-04\r\n",
    "Epoch 3/5\r\n",
    "1000/1000 [==============================] - 41s 41ms/step - loss: 2.3637e-04 - val_loss: 2.4041e-04\r\n",
    "Epoch 4/5\r\n",
    "1000/1000 [==============================] - 40s 40ms/step - loss: 2.4011e-04 - val_loss: 2.2581e-04\r\n",
    "Epoch 5/5\r\n",
    "1000/1000 [==============================] - 40s 40ms/step - loss: 2.2561e-04 - val_loss: 1.8994e-04\r\n",
    "\r\n",
    "\r\n",
    "# sigmoid mixet\r\n",
    "Epoch 1/3\r\n",
    "1000/1000 [==============================] - 44s 41ms/step - loss: 0.0058 - val_loss: 2.8256e-04\r\n",
    "Epoch 2/3\r\n",
    "1000/1000 [==============================] - 40s 40ms/step - loss: 2.5486e-04 - val_loss: 2.3813e-04\r\n",
    "Epoch 3/3\r\n",
    "1000/1000 [==============================] - 41s 41ms/step - loss: 2.4014e-04 - val_loss: 2.2840e-04\r\n",
    "\r\n",
    "\r\n",
    "# tanh\r\n",
    "Epoch 1/3\r\n",
    "1000/1000 [==============================] - 43s 37ms/step - loss: 0.0056 - val_loss: 2.8310e-04\r\n",
    "Epoch 2/3\r\n",
    "1000/1000 [==============================] - 36s 36ms/step - loss: 2.4773e-04 - val_loss: 2.4905e-04\r\n",
    "Epoch 3/3\r\n",
    "1000/1000 [==============================] - 38s 38ms/step - loss: 2.3715e-04 - val_loss: 2.3028e-04\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "\"save the encoder part as tokenizer\"\r\n",
    "tokenizer = tf.keras.Model(model.input, model.get_layer('tokenizer').output)\r\n",
    "tokenizer.compile('adam')\r\n",
    "tokenizer.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "token (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rec_vec (RecVec)                (None, 17, 16)       0           token[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "encoder_start (Dense)           (None, 17, 16)       272         rec_vec[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 17, 16)       32          encoder_start[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_portable ( (None, 17, 16)       6448        layer_normalization[0][0]        \n",
      "                                                                 layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 17, 16)       0           multi_head_attention_portable[0][\n",
      "                                                                 layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 17, 16)       32          add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 17, 32)       544         layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 17, 16)       528         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 17, 16)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 17, 16)       0           dropout[0][0]                    \n",
      "                                                                 layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_2 (LayerNor (None, 17, 16)       32          add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_portable_1 (None, 17, 16)       6448        layer_normalization_2[0][0]      \n",
      "                                                                 layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 17, 16)       0           multi_head_attention_portable_1[0\n",
      "                                                                 layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, 17, 16)       32          add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 17, 32)       544         layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 17, 16)       528         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 17, 16)       0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 17, 16)       0           dropout_1[0][0]                  \n",
      "                                                                 layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_4 (LayerNor (None, 17, 16)       32          add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_portable_2 (None, 17, 16)       6448        layer_normalization_4[0][0]      \n",
      "                                                                 layer_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 17, 16)       0           multi_head_attention_portable_2[0\n",
      "                                                                 layer_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_5 (LayerNor (None, 17, 16)       32          add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 17, 32)       544         layer_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 17, 16)       528         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 17, 16)       0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 17, 16)       0           dropout_2[0][0]                  \n",
      "                                                                 layer_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_6 (LayerNor (None, 17, 16)       32          add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 17, 16)       0           layer_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tokenizer (Flatten)             (None, 272)          0           activation[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 23,056\n",
      "Trainable params: 23,056\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "tokenizer.save(save_path)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:Found untraced functions such as query_layer_call_and_return_conditional_losses, query_layer_call_fn, key_layer_call_and_return_conditional_losses, key_layer_call_fn, value_layer_call_and_return_conditional_losses while saving (showing 5 of 90). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: ../tmp/bert_auto_model\\assets\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\elie\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n",
      "INFO:tensorflow:Assets written to: ../tmp/bert_auto_model\\assets\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "cada0c3e68bbe3038c05f3f13c34d05fb5411cc128b62a4a529880c33c3268c3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}